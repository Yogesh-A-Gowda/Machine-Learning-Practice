{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059e5eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a93668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "your_token = os.getenv(\"HF\")\n",
    "# Log in using the token\n",
    "login(token=your_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9263232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "#first run the following line, once its executed, comment it out, and then change the model path.\n",
    "# models would be stored in C:/yogesh.gowda/cache/huggingface/hub/ -> cut and paste the model folder to your desired location and provide the path below.\n",
    "\n",
    "#pipe = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "#Make sure path lenght is less than 96 characters for Windows OS, and prefix the path with r\n",
    "\n",
    "\n",
    "    \n",
    "pipe = pipeline(\"summarization\", model=r\"C:\\models--sshleifer--distilbart-cnn-12-6\\snapshots\\a4f8f3ea906ed274767e9906dbaede7531d660ff\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f70d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\yogesh.gowda\\AppData\\Local\\Temp\\ipykernel_8488\\1893257361.py:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  texts = '''Solution: Fix the Path String\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Python will ignore all escape sequences . You need to tell Python to treat the backslashes literally . There are two simple and recommended ways to fix this: Use a Raw String (Easiest and Recommended)Prefix your string with an r to make it a raw string .\n"
     ]
    }
   ],
   "source": [
    "texts = ''''''\n",
    "summary = pipe(texts)\n",
    "print(summary[0]['summary_text'])\n",
    "\n",
    "def summary(text):\n",
    "    summarized_text = pipe(text)\n",
    "    return summarized_text[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1762eecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (319172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py\", line 1623, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\utils.py\", line 915, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yogesh.gowda\\AppData\\Local\\Temp\\ipykernel_8488\\1893257361.py\", line 35, in summary\n",
      "    summarized_text = pipe(text)\n",
      "                      ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 303, in __call__\n",
      "    return super().__call__(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 191, in __call__\n",
      "    result = super().__call__(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 1467, in __call__\n",
      "    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 1474, in run_single\n",
      "    model_outputs = self.forward(model_inputs, **forward_params)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 1374, in forward\n",
      "    model_outputs = self._forward(model_inputs, **forward_params)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py\", line 220, in _forward\n",
      "    output_ids = self.model.generate(**model_inputs, **generate_kwargs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\utils.py\", line 2465, in generate\n",
      "    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\utils.py\", line 861, in _prepare_encoder_decoder_kwargs_for_generation\n",
      "    model_kwargs[\"encoder_outputs\"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore\n",
      "                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\", line 838, in forward\n",
      "    embed_pos = self.embed_positions(input)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\", line 103, in forward\n",
      "    return super().forward(position_ids + self.offset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py\", line 192, in forward\n",
      "    return F.embedding(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yogesh.gowda\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py\", line 2546, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "IndexError: index out of range in self\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()\n",
    "\n",
    "demo = gr.Interface(fn=summary, inputs=\"text\", outputs=\"text\", title=\"Text Summarizer\", description=\"Enter text to summarize using a pre-trained model.\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b90dd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
